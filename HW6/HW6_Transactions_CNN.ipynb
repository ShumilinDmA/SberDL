{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dcd0989",
   "metadata": {},
   "source": [
    "## Making datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9181c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1fa7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = \"data/train_encoded.pickle\"\n",
    "VALID_DATA = \"data/valid_encoded.pickle\"\n",
    "TEST_DATA = \"data/test_encoded.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafaa847",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATA, \"rb\") as file:\n",
    "    train_df = pickle.load(file)\n",
    "    train_df.sort_values(by='Date', inplace=True)\n",
    "    \n",
    "    \n",
    "with open(VALID_DATA, \"rb\") as file:\n",
    "    valid_df = pickle.load(file)\n",
    "    valid_df.sort_values(by='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22ab36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Card</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Use Chip</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Errors</th>\n",
       "      <th>IsFraud_target</th>\n",
       "      <th>Date</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Time_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Dow_sin</th>\n",
       "      <th>Dow_cos</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>Minute_sin</th>\n",
       "      <th>Minute_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-02 07:10:00</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>-68.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-02 07:17:00</td>\n",
       "      <td>130</td>\n",
       "      <td>420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>9.781476e-01</td>\n",
       "      <td>-0.207912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>113.620003</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-02 07:21:00</td>\n",
       "      <td>129</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>8.090170e-01</td>\n",
       "      <td>-0.587785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>114.730003</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-02 17:30:00</td>\n",
       "      <td>129</td>\n",
       "      <td>36540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>5.665539e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>251.710007</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-03 09:03:00</td>\n",
       "      <td>129</td>\n",
       "      <td>55980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>3.090170e-01</td>\n",
       "      <td>0.951057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User  Card      Amount  Use Chip  MCC  Errors  IsFraud_target  \\\n",
       "0   791     0   68.000000         9   12     121               1   \n",
       "1   791     0  -68.000000         9   12     121               1   \n",
       "2   791     0  113.620003         9   12     121               1   \n",
       "3   791     0  114.730003         9   13     121               1   \n",
       "4   791     0  251.710007         9   14     121               1   \n",
       "\n",
       "                 Date  Outcome  Time_diff  ...  Month_sin  Month_cos  \\\n",
       "0 1991-01-02 07:10:00      129          0  ...        0.5   0.866025   \n",
       "1 1991-01-02 07:17:00      130        420  ...        0.5   0.866025   \n",
       "2 1991-01-02 07:21:00      129        240  ...        0.5   0.866025   \n",
       "3 1991-01-02 17:30:00      129      36540  ...        0.5   0.866025   \n",
       "4 1991-01-03 09:03:00      129      55980  ...        0.5   0.866025   \n",
       "\n",
       "    Day_sin   Day_cos   Dow_sin   Dow_cos  Hour_sin  Hour_cos    Minute_sin  \\\n",
       "0  0.394356  0.918958  0.974928 -0.222521  0.965926 -0.258819  8.660254e-01   \n",
       "1  0.394356  0.918958  0.974928 -0.222521  0.965926 -0.258819  9.781476e-01   \n",
       "2  0.394356  0.918958  0.974928 -0.222521  0.965926 -0.258819  8.090170e-01   \n",
       "3  0.394356  0.918958  0.974928 -0.222521 -0.965926 -0.258819  5.665539e-16   \n",
       "4  0.571268  0.820763  0.433884 -0.900969  0.707107 -0.707107  3.090170e-01   \n",
       "\n",
       "   Minute_cos  \n",
       "0    0.500000  \n",
       "1   -0.207912  \n",
       "2   -0.587785  \n",
       "3   -1.000000  \n",
       "4    0.951057  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba636ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"Card\", \"Use Chip\", \"MCC\", \"Errors\", \"Outcome\", \"is_diff_merchant\",\n",
    "               \"is_diff_merchant_city\", \"is_diff_merchant_state\"]\n",
    "target_columns = [\"IsFraud_target\"]\n",
    "drop_columns = [\"User\", \"Date\"]\n",
    "num_columns = np.setdiff1d(train_df.columns.tolist(), cat_columns+target_columns+drop_columns).tolist()\n",
    "\n",
    "assert len(train_df.columns) == len(cat_columns+target_columns+drop_columns+num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca90623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, cat_columns, num_columns, target_columns, drop_columns, max_latest_seq=None):\n",
    "        self.df = df\n",
    "        self.cat_columns = cat_columns\n",
    "        self.num_columns = num_columns\n",
    "        self.target_columns = target_columns\n",
    "        self.drop_columns = drop_columns\n",
    "        self.max_latest_seq = max_latest_seq\n",
    "        self.indx_to_user = {i: user for i, user in enumerate(self.df.User.unique())}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indx_to_user)\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        user_id = self.indx_to_user[indx]\n",
    "        user_data = (self.df.loc[self.df.loc[:, 'User']==user_id, :]\n",
    "                     .drop(columns=self.drop_columns)\n",
    "                     .reset_index(drop=True))\n",
    "        \n",
    "        if self.max_latest_seq:\n",
    "            if len(user_data)>self.max_latest_seq:\n",
    "                user_data = user_data[-self.max_latest_seq:]\n",
    "                \n",
    "        cat_data = user_data[self.cat_columns].to_numpy()\n",
    "        num_data = user_data[self.num_columns].to_numpy()\n",
    "        target = np.unique(user_data[self.target_columns].to_numpy())[0]\n",
    "        return cat_data, num_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdfbe52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    category_data = []\n",
    "    numerical_data = []\n",
    "    target_data = []\n",
    "    for category, numerical, target in batch:\n",
    "        category_data.append(torch.LongTensor(category))\n",
    "        numerical_data.append(torch.Tensor(numerical))\n",
    "        target_data.append(target)\n",
    "        \n",
    "    category_data = torch.nn.utils.rnn.pad_sequence(category_data, batch_first=True, padding_value=137)\n",
    "#     numerical_data = torch.nn.utils.rnn.pad_sequence(numerical_data, batch_first=True, padding_value=0)\n",
    "\n",
    "    target_data = torch.LongTensor(target_data)\n",
    "    \n",
    "    return category_data, numerical_data, target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21b43f",
   "metadata": {},
   "source": [
    "## CNN settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "346e3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_numerical_col = len(num_columns)  # Constant\n",
    "NUM_UNIQ_EMBEDDINGS = 138  # Constant\n",
    "\n",
    "MAX_LATEST_SEQ = 32\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 5\n",
    "feature_dim = n_numerical_col+len(cat_columns)*EMBEDDING_DIM\n",
    "DROPOUT = 0.2\n",
    "KERNEL_SIZES = [2,3,4]\n",
    "OUT_CHANNELS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317436a",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f20a3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, cat_columns=cat_columns,\n",
    "                              num_columns=num_columns,\n",
    "                              target_columns=target_columns,\n",
    "                              drop_columns=drop_columns,\n",
    "                              max_latest_seq=MAX_LATEST_SEQ)\n",
    "\n",
    "valid_dataset = CustomDataset(valid_df, cat_columns=cat_columns,\n",
    "                              num_columns=num_columns,\n",
    "                              target_columns=target_columns,\n",
    "                              drop_columns=drop_columns,\n",
    "                              max_latest_seq=MAX_LATEST_SEQ)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8a165",
   "metadata": {},
   "source": [
    "### Default predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c114ef68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant prediction accuracy: 0.602142870426178\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.cat([y for cat, num, y in train_loader])\n",
    "y_hat = torch.zeros_like(y_true)\n",
    "constant_accuracy = (y_true==y_hat).sum()/len(y_true)\n",
    "print(f\"Constant prediction accuracy: {constant_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ab949c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random prediction accuracy: 0.602142870426178\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.randint(0, 1, (1400,))\n",
    "random_accuracy = (y_true==y_hat).sum()/len(y_true)\n",
    "print(f\"Random prediction accuracy: {random_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894e497",
   "metadata": {},
   "source": [
    "### CNN Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "efeadd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNetwork(nn.Module):\n",
    "    def __init__(self,\n",
    "                num_uniq_embeddings,\n",
    "                embedding_dim,\n",
    "                n_numerical_col,\n",
    "                feature_dim,\n",
    "                out_channels,\n",
    "                kernel_sizes,\n",
    "                dropout):\n",
    "        super(CNNNetwork, self).__init__()\n",
    "        \n",
    "        self.num_uniq_embeddings=num_uniq_embeddings\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.n_numerical_col=n_numerical_col\n",
    "        self.feature_dim = feature_dim\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.num_uniq_embeddings, self.embedding_dim)\n",
    "        self.batch_norm = nn.BatchNorm1d(self.n_numerical_col)\n",
    "        \n",
    "        self.conv_list = nn.ModuleList([nn.Conv1d(in_channels=self.feature_dim,\n",
    "                                                  out_channels=self.out_channels,\n",
    "                                                  kernel_size=(kernel_size,)) for kernel_size in self.kernel_sizes])\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(len(kernel_sizes) * out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(kernel_sizes) * out_channels, len(kernel_sizes) * out_channels)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(len(kernel_sizes) * out_channels)\n",
    "        self.fc2 = nn.Linear(len(kernel_sizes) * out_channels, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        cat, num = batch\n",
    "        \n",
    "        # Concat embeddings\n",
    "        cat = self.embedding(cat)\n",
    "        all_but_last_two_dims = cat.size()[:-2]\n",
    "        cat = cat.view(*all_but_last_two_dims, -1)\n",
    "        \n",
    "        # Batchnorm across numeric features and pack it to tensor\n",
    "        num = [self.batch_norm(numeric) for numeric in num]\n",
    "        num = torch.nn.utils.rnn.pad_sequence(num, batch_first=True, padding_value=0)\n",
    "        \n",
    "        # Concat all features\n",
    "        embedded = torch.cat((num, cat), dim=-1) # [batch_size, seq_len, emb_dim]\n",
    "        \n",
    "        embedded = embedded.permute(0, 2, 1) # [batch_size, emb_dim, seq_len]\n",
    "        \n",
    "        convoluted = [F.relu(conv(embedded)) for conv in self.conv_list] # [batch_size, out_channel, seq_len-(kernel-1)]\n",
    "        \n",
    "        pooled = [F.max_pool1d(x_conv, x_conv.shape[2]) for x_conv in convoluted]\n",
    "        \n",
    "        x = self.batchnorm1(torch.cat(pooled, dim=1).squeeze(2))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.fc2(x)\n",
    "      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "57eeba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNNetwork(num_uniq_embeddings=NUM_UNIQ_EMBEDDINGS,\n",
    "               embedding_dim=EMBEDDING_DIM,\n",
    "               n_numerical_col=n_numerical_col,\n",
    "                feature_dim=feature_dim,\n",
    "                  out_channels=OUT_CHANNELS,\n",
    "                  kernel_sizes=KERNEL_SIZES,\n",
    "                  dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "757a1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat, num, y in valid_loader:\n",
    "    output=model((cat, num))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fef3960c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3844893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "\n",
    "class LightningWrapper(pl.LightningModule):\n",
    "    def __init__(self, model, cfg=None):\n",
    "        super(LightningWrapper, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.model = model\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_cat, x_num, y = batch\n",
    "        pred = self.model((x_cat, x_num))\n",
    "        loss = self.criterion(pred, y)\n",
    "        y_softmax = torch.softmax(pred, dim=-1).detach()\n",
    "        y_pred = torch.argmax(y_softmax, dim=-1)\n",
    "        y_proba = y_softmax[:,1]\n",
    "        return {\"loss\": loss, \"y_pred\": y_pred, \"y_true\": y, \"y_proba\": y_proba}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_cat, x_num, y = batch\n",
    "        pred = self.model((x_cat, x_num))\n",
    "        loss = self.criterion(pred, y)\n",
    "        y_softmax = torch.softmax(pred, dim=-1).detach()\n",
    "        y_pred = torch.argmax(y_softmax, dim=-1)\n",
    "        y_proba = y_softmax[:,1]\n",
    "        return {\"val_loss\": loss, \"y_pred\": y_pred, \"y_true\": y, \"y_proba\": y_proba}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=3e-4)\n",
    "        lr_schedulers = {'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5),\n",
    "                         'monitor': 'val_loss'}\n",
    "        return [optimizer], [lr_schedulers]\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        y_hat = torch.cat([x['y_pred'].view(-1) for x in outputs])\n",
    "        y_true = torch.cat([x['y_true'].view(-1) for x in outputs])\n",
    "        y_proba = torch.cat([x['y_proba'].view(-1) for x in outputs])\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        \n",
    "        roc_auc = float(torchmetrics.functional.auroc(preds=y_proba, target=y_true, pos_label=1))\n",
    "        f1_score = float(torchmetrics.functional.f1(preds=y_proba, target=y_true))\n",
    "        accuracy = float(torchmetrics.functional.accuracy(preds=y_hat, target=y_true))\n",
    "        print(f'Train: \\n   Loss: {avg_loss}, F1 score: {f1_score}, ROC_AUC: {roc_auc}, Accuracy: {accuracy}')\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        y_hat = torch.cat([x['y_pred'].view(-1) for x in outputs])\n",
    "        y_true = torch.cat([x['y_true'].view(-1) for x in outputs])\n",
    "        y_proba = torch.cat([x['y_proba'].view(-1) for x in outputs])\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "\n",
    "        \n",
    "        roc_auc = float(torchmetrics.functional.auroc(preds=y_proba, target=y_true, pos_label=1))\n",
    "        f1_score = float(torchmetrics.functional.f1(preds=y_proba, target=y_true))\n",
    "        accuracy = float(torchmetrics.functional.accuracy(preds=y_hat, target=y_true))\n",
    "        \n",
    "        self.log('val_loss', avg_loss)\n",
    "        \n",
    "        print(f'Valid {self.current_epoch}: \\n   Loss: {avg_loss}, F1 score: {f1_score}, ROC_AUC: {roc_auc}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d948ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = LightningWrapper(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "776f80f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83180590",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | CNNNetwork       | 25.7 K\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "25.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.7 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/SberDL/HW6/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid 0: \n",
      "   Loss: 0.6541346311569214, F1 score: 0.7692307829856873, ROC_AUC: 0.6958333849906921, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/SberDL/HW6/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b0639d0910457c96019736654f64d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: \n",
      "   Loss: 0.7127112150192261, F1 score: 0.5114378929138184, ROC_AUC: 0.5968340039253235, Accuracy: 0.572857141494751\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid 0: \n",
      "   Loss: 0.6849370002746582, F1 score: 0.5600000023841858, ROC_AUC: 0.6699939966201782, Accuracy: 0.6333333253860474\n",
      "Train: \n",
      "   Loss: 0.6368815898895264, F1 score: 0.5657092928886414, ROC_AUC: 0.6803328990936279, Accuracy: 0.6435714364051819\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid 1: \n",
      "   Loss: 1.6266918182373047, F1 score: 0.5691056251525879, ROC_AUC: 0.6725242733955383, Accuracy: 0.6466666460037231\n",
      "Train: \n",
      "   Loss: 0.6012115478515625, F1 score: 0.6046915054321289, ROC_AUC: 0.724643349647522, Accuracy: 0.675000011920929\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid 2: \n",
      "   Loss: 0.8081352710723877, F1 score: 0.5550661087036133, ROC_AUC: 0.6789544224739075, Accuracy: 0.6633333563804626\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model_wrapper, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6f5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
