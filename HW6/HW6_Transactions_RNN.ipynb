{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dcd0989",
   "metadata": {},
   "source": [
    "## Making datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9181c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf1fa7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = \"data/train_encoded.pickle\"\n",
    "VALID_DATA = \"data/valid_encoded.pickle\"\n",
    "TEST_DATA = \"data/test_encoded.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aafaa847",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATA, \"rb\") as file:\n",
    "    train_df = pickle.load(file)\n",
    "    train_df.sort_values(by='Date', inplace=True)\n",
    "    \n",
    "    \n",
    "with open(VALID_DATA, \"rb\") as file:\n",
    "    valid_df = pickle.load(file)\n",
    "    valid_df.sort_values(by='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b22ab36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Card</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Use Chip</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Errors</th>\n",
       "      <th>IsFraud_target</th>\n",
       "      <th>Date</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Time_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Dow_sin</th>\n",
       "      <th>Dow_cos</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "      <th>Minute_sin</th>\n",
       "      <th>Minute_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-02 07:10:00</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>-68.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-02 07:17:00</td>\n",
       "      <td>130</td>\n",
       "      <td>420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>9.781476e-01</td>\n",
       "      <td>-0.207912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>113.620003</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-02 07:21:00</td>\n",
       "      <td>129</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>8.090170e-01</td>\n",
       "      <td>-0.587785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>114.730003</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-02 17:30:00</td>\n",
       "      <td>129</td>\n",
       "      <td>36540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>5.665539e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>791</td>\n",
       "      <td>0</td>\n",
       "      <td>251.710007</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-01-03 09:03:00</td>\n",
       "      <td>129</td>\n",
       "      <td>55980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>3.090170e-01</td>\n",
       "      <td>0.951057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User  Card      Amount  Use Chip  MCC  Errors  IsFraud_target  \\\n",
       "0   791     0   68.000000         9   12     121               1   \n",
       "1   791     0  -68.000000         9   12     121               1   \n",
       "2   791     0  113.620003         9   12     121               1   \n",
       "3   791     0  114.730003         9   13     121               1   \n",
       "4   791     0  251.710007         9   14     121               1   \n",
       "\n",
       "                 Date  Outcome  Time_diff  ...  Month_sin  Month_cos  \\\n",
       "0 1991-01-02 07:10:00      129          0  ...        0.5   0.866025   \n",
       "1 1991-01-02 07:17:00      130        420  ...        0.5   0.866025   \n",
       "2 1991-01-02 07:21:00      129        240  ...        0.5   0.866025   \n",
       "3 1991-01-02 17:30:00      129      36540  ...        0.5   0.866025   \n",
       "4 1991-01-03 09:03:00      129      55980  ...        0.5   0.866025   \n",
       "\n",
       "    Day_sin   Day_cos   Dow_sin   Dow_cos  Hour_sin  Hour_cos    Minute_sin  \\\n",
       "0  0.394356  0.918958  0.974928 -0.222521  0.965926 -0.258819  8.660254e-01   \n",
       "1  0.394356  0.918958  0.974928 -0.222521  0.965926 -0.258819  9.781476e-01   \n",
       "2  0.394356  0.918958  0.974928 -0.222521  0.965926 -0.258819  8.090170e-01   \n",
       "3  0.394356  0.918958  0.974928 -0.222521 -0.965926 -0.258819  5.665539e-16   \n",
       "4  0.571268  0.820763  0.433884 -0.900969  0.707107 -0.707107  3.090170e-01   \n",
       "\n",
       "   Minute_cos  \n",
       "0    0.500000  \n",
       "1   -0.207912  \n",
       "2   -0.587785  \n",
       "3   -1.000000  \n",
       "4    0.951057  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba636ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"Card\", \"Use Chip\", \"MCC\", \"Errors\", \"Outcome\", \"is_diff_merchant\",\n",
    "               \"is_diff_merchant_city\", \"is_diff_merchant_state\"]\n",
    "target_columns = [\"IsFraud_target\"]\n",
    "drop_columns = [\"User\", \"Date\"]\n",
    "num_columns = np.setdiff1d(train_df.columns.tolist(), cat_columns+target_columns+drop_columns).tolist()\n",
    "\n",
    "assert len(train_df.columns) == len(cat_columns+target_columns+drop_columns+num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca90623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, cat_columns, num_columns, target_columns, drop_columns, max_latest_seq=None):\n",
    "        self.df = df\n",
    "        self.cat_columns = cat_columns\n",
    "        self.num_columns = num_columns\n",
    "        self.target_columns = target_columns\n",
    "        self.drop_columns = drop_columns\n",
    "        self.max_latest_seq = max_latest_seq\n",
    "        self.indx_to_user = {i: user for i, user in enumerate(self.df.User.unique())}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indx_to_user)\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        user_id = self.indx_to_user[indx]\n",
    "        user_data = (self.df.loc[self.df.loc[:, 'User']==user_id, :]\n",
    "                     .drop(columns=self.drop_columns)\n",
    "                     .reset_index(drop=True))\n",
    "        \n",
    "        if self.max_latest_seq:\n",
    "            if len(user_data)>self.max_latest_seq:\n",
    "                user_data = user_data[-self.max_latest_seq:]\n",
    "                \n",
    "        cat_data = user_data[self.cat_columns].to_numpy()\n",
    "        num_data = user_data[self.num_columns].to_numpy()\n",
    "        target = np.unique(user_data[self.target_columns].to_numpy())[0]\n",
    "        return cat_data, num_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdfbe52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    category_data = []\n",
    "    numerical_data = []\n",
    "    target_data = []\n",
    "    for category, numerical, target in batch:\n",
    "        category_data.append(torch.LongTensor(category))\n",
    "        numerical_data.append(torch.Tensor(numerical))\n",
    "        target_data.append(target)\n",
    "        \n",
    "    category_data = torch.nn.utils.rnn.pad_sequence(category_data, batch_first=True, padding_value=137)\n",
    "#     numerical_data = torch.nn.utils.rnn.pad_sequence(numerical_data, batch_first=True, padding_value=0)\n",
    "\n",
    "    target_data = torch.LongTensor(target_data)\n",
    "    \n",
    "    return category_data, numerical_data, target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21b43f",
   "metadata": {},
   "source": [
    "## LSTM settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346e3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_numerical_col = len(num_columns)  # Constant\n",
    "NUM_UNIQ_EMBEDDINGS = 138  # Constant\n",
    "\n",
    "MAX_LATEST_SEQ = 32\n",
    "BATCH_SIZE = 50\n",
    "EMBEDDING_DIM = 5\n",
    "feature_dim = n_numerical_col+len(cat_columns)*EMBEDDING_DIM\n",
    "N_LSTM_LAYER = 2\n",
    "HIDDEN_DIM = 128\n",
    "DROPOUT = 0.2\n",
    "BIDIRECTIONAL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317436a",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20a3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, cat_columns=cat_columns,\n",
    "                              num_columns=num_columns,\n",
    "                              target_columns=target_columns,\n",
    "                              drop_columns=drop_columns,\n",
    "                              max_latest_seq=MAX_LATEST_SEQ)\n",
    "\n",
    "valid_dataset = CustomDataset(valid_df, cat_columns=cat_columns,\n",
    "                              num_columns=num_columns,\n",
    "                              target_columns=target_columns,\n",
    "                              drop_columns=drop_columns,\n",
    "                              max_latest_seq=MAX_LATEST_SEQ)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8a165",
   "metadata": {},
   "source": [
    "### Default predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c114ef68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant prediction accuracy: 0.602142870426178\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.cat([y for cat, num, y in train_loader])\n",
    "y_hat = torch.zeros_like(y_true)\n",
    "constant_accuracy = (y_true==y_hat).sum()/len(y_true)\n",
    "print(f\"Constant prediction accuracy: {constant_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ab949c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random prediction accuracy: 0.602142870426178\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.randint(0, 1, (1400,))\n",
    "random_accuracy = (y_true==y_hat).sum()/len(y_true)\n",
    "print(f\"Random prediction accuracy: {random_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894e497",
   "metadata": {},
   "source": [
    "### RNN Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efeadd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_network(nn.Module):\n",
    "    def __init__(self,\n",
    "                num_uniq_embeddings,\n",
    "                embedding_dim,\n",
    "                feature_dim,\n",
    "                n_lstm_layer,\n",
    "                hidden_dim,\n",
    "                dropout,\n",
    "                bidirectional,\n",
    "                n_numerical_col):\n",
    "        super(RNN_network, self).__init__()\n",
    "        \n",
    "        self.num_uniq_embeddings=num_uniq_embeddings\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.feature_dim=feature_dim\n",
    "        self.n_lstm_layer=n_lstm_layer\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.dropout=dropout if n_lstm_layer>1 else 0\n",
    "        self.bidirectional=bidirectional\n",
    "        self.n_numerical_col=n_numerical_col\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.num_uniq_embeddings, self.embedding_dim)\n",
    "        self.batch_norm = nn.BatchNorm1d(self.n_numerical_col)\n",
    "        self.rnn = nn.LSTM(input_size=self.feature_dim,\n",
    "                          num_layers=self.n_lstm_layer,\n",
    "                          hidden_size=self.hidden_dim,\n",
    "                          batch_first=True,\n",
    "                          dropout=self.dropout,\n",
    "                          bidirectional=self.bidirectional)\n",
    "        \n",
    "        self.linear_one = nn.Linear(self.hidden_dim*(self.bidirectional+1), self.hidden_dim)\n",
    "        self.batchnorm_linear = nn.BatchNorm1d(self.hidden_dim)\n",
    "        self.linear_two = nn.Linear(self.hidden_dim, 2)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        cat, num = batch\n",
    "        \n",
    "        # Concat embeddings\n",
    "        cat = self.embedding(cat)\n",
    "        all_but_last_two_dims = cat.size()[:-2]\n",
    "        cat = cat.view(*all_but_last_two_dims, -1)\n",
    "        \n",
    "        # Batchnorm across numeric features and pack it to tensor\n",
    "        num = [self.batch_norm(numeric) for numeric in num]\n",
    "        num = torch.nn.utils.rnn.pad_sequence(num, batch_first=True, padding_value=0)\n",
    "        \n",
    "        # Concat all features\n",
    "        batch = torch.cat((num, cat), dim=-1)\n",
    "        \n",
    "        out, (hidden, cell) = self.rnn(batch)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            to_classifier = torch.cat((hidden[-2], hidden[-1]), dim=-1)\n",
    "        else:\n",
    "            to_classifier = hidden[-1]\n",
    "            \n",
    "        x = F.relu(self.linear_one(to_classifier))\n",
    "        x = self.batchnorm_linear(x)\n",
    "        output = self.linear_two(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57eeba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_network(num_uniq_embeddings=NUM_UNIQ_EMBEDDINGS,\n",
    "               embedding_dim=EMBEDDING_DIM,\n",
    "               feature_dim=feature_dim,\n",
    "               n_lstm_layer=N_LSTM_LAYER,\n",
    "               hidden_dim=HIDDEN_DIM,\n",
    "               dropout=DROPOUT,\n",
    "               bidirectional=BIDIRECTIONAL,\n",
    "               n_numerical_col=n_numerical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "757a1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat, num, y in valid_loader:\n",
    "    output=model((cat, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3844893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "\n",
    "class LightningWrapper(pl.LightningModule):\n",
    "    def __init__(self, model, cfg=None):\n",
    "        super(LightningWrapper, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.model = model\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_cat, x_num, y = batch\n",
    "        pred = self.model((x_cat, x_num))\n",
    "        loss = self.criterion(pred, y)\n",
    "        y_softmax = torch.softmax(pred, dim=-1).detach()\n",
    "        y_pred = torch.argmax(y_softmax, dim=-1)\n",
    "        y_proba = y_softmax[:,1]\n",
    "        return {\"loss\": loss, \"y_pred\": y_pred, \"y_true\": y, \"y_proba\": y_proba}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_cat, x_num, y = batch\n",
    "        pred = self.model((x_cat, x_num))\n",
    "        loss = self.criterion(pred, y)\n",
    "        y_softmax = torch.softmax(pred, dim=-1).detach()\n",
    "        y_pred = torch.argmax(y_softmax, dim=-1)\n",
    "        y_proba = y_softmax[:,1]\n",
    "        return {\"val_loss\": loss, \"y_pred\": y_pred, \"y_true\": y, \"y_proba\": y_proba}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=3e-4)\n",
    "        lr_schedulers = {'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5),\n",
    "                         'monitor': 'val_loss'}\n",
    "        return [optimizer], [lr_schedulers]\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        y_hat = torch.cat([x['y_pred'].view(-1) for x in outputs])\n",
    "        y_true = torch.cat([x['y_true'].view(-1) for x in outputs])\n",
    "        y_proba = torch.cat([x['y_proba'].view(-1) for x in outputs])\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        \n",
    "        roc_auc = float(torchmetrics.functional.auroc(preds=y_proba, target=y_true, pos_label=1))\n",
    "        f1_score = float(torchmetrics.functional.f1(preds=y_proba, target=y_true))\n",
    "        accuracy = float(torchmetrics.functional.accuracy(preds=y_hat, target=y_true))\n",
    "        print(f'Train: \\n   Loss: {avg_loss}, F1 score: {f1_score}, ROC_AUC: {roc_auc}, Accuracy: {accuracy}')\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        y_hat = torch.cat([x['y_pred'].view(-1) for x in outputs])\n",
    "        y_true = torch.cat([x['y_true'].view(-1) for x in outputs])\n",
    "        y_proba = torch.cat([x['y_proba'].view(-1) for x in outputs])\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "\n",
    "        \n",
    "        roc_auc = float(torchmetrics.functional.auroc(preds=y_proba, target=y_true, pos_label=1))\n",
    "        f1_score = float(torchmetrics.functional.f1(preds=y_proba, target=y_true))\n",
    "        accuracy = float(torchmetrics.functional.accuracy(preds=y_hat, target=y_true))\n",
    "        \n",
    "        self.log('val_loss', avg_loss)\n",
    "        \n",
    "        print(f'Valid {self.current_epoch}: \\n   Loss: {avg_loss}, F1 score: {f1_score}, ROC_AUC: {roc_auc}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d948ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = LightningWrapper(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "776f80f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83180590",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | RNN_network      | 615 K \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "615 K     Trainable params\n",
      "0         Non-trainable params\n",
      "615 K     Total params\n",
      "2.463     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/SberDL/HW6/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid 0: \n",
      "   Loss: 0.6857054233551025, F1 score: 0.7261146903038025, ROC_AUC: 0.5528355836868286, Accuracy: 0.5699999928474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/SberDL/HW6/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ca1b4b41194d66958fe60b760f1f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003\n",
      "Train: \n",
      "   Loss: 0.6603348851203918, F1 score: 0.5870569944381714, ROC_AUC: 0.6845752596855164, Accuracy: 0.6171428561210632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid 0: \n",
      "   Loss: 0.684273898601532, F1 score: 0.18309859931468964, ROC_AUC: 0.5498862266540527, Accuracy: 0.6133333444595337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/SberDL/HW6/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model_wrapper, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392156b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
