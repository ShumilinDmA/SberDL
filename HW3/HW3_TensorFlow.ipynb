{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64cd75df",
   "metadata": {},
   "source": [
    "## HW3 - Neural Net using TensorFlow\n",
    "Реализовать двухслойную полносвязную нейросетку на чистом TF. Как функцию активации можете использовать что хотите. Размер тоже на ваше усмотрение. Предлагаю сделать по образу и подобию тетрадки с пары.\n",
    "\n",
    "Для fashion mnist:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db531145",
   "metadata": {},
   "source": [
    "### Data Loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b4b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5823c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1998\n",
    "tf.random.set_seed(SEED) # фиксируем random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f744130",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b0489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10**4, random_state=SEED)\n",
    "\n",
    "X_train = X_train/ 255.\n",
    "X_val = X_val/ 255.\n",
    "X_test = X_test/ 255.\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28**2)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28**2)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28**2)\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28355bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "y_val_ohe = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184c2012",
   "metadata": {},
   "source": [
    "### Auxiliary finctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b24d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(p_pred, y_true):\n",
    "    p_pred = tf.clip_by_value(p_pred, 1e-9, 1.)\n",
    "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(p_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "735c270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predict_proba, target):\n",
    "    target = tf.math.argmax(target, axis=-1, output_type=tf.dtypes.int64)\n",
    "    predict = tf.math.argmax(predict_proba, axis=-1, output_type=tf.dtypes.int64)\n",
    "    return (predict==target).numpy().sum()/len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e147957",
   "metadata": {},
   "source": [
    "### Constructing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1cede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random.normal([784, 256], mean=0, stddev=0.01, seed=SEED), name='weight_1')\n",
    "b1 = tf.Variable(tf.random.normal([1, 256],  mean=0, stddev=0.01, seed=SEED), name='bias_1')\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([256,10],  mean=0, stddev=0.01, seed=SEED), name='weight_2')\n",
    "b2 = tf.Variable(tf.random.normal([1,10],  mean=0, stddev=0.01, seed=SEED) , name='bias_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0782b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp = tf.math.exp(x)\n",
    "    exp_sum = tf.reduce_sum(exp, axis=-1)\n",
    "    exp = tf.transpose(exp)\n",
    "    result = tf.math.divide_no_nan(exp, exp_sum)\n",
    "    result = tf.transpose(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ada12e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    x = X@W1+b1\n",
    "    x = tf.clip_by_value(x, 0., tf.float32.max)\n",
    "    x = x@W2+b2\n",
    "    x = softmax(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37e3b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X_test[:5]\n",
    "# Y = y_test_ohe[:5]\n",
    "# predict_proba = model(X)\n",
    "# logloss(predict_proba, Y)\n",
    "# accuracy(predict_proba, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034dfd2",
   "metadata": {},
   "source": [
    "### Fitting the model on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f9977f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74cd4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X, Y):\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "        predict_proba = model(X)\n",
    "        loss = logloss(predict_proba, Y)\n",
    "\n",
    "    gradients = g.gradient(loss, [W1, b1, W2, b2])\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, [W1, b1, W2, b2]))\n",
    "    \n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba4cd07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 2.303663969039917, valid loss: 2.0003325939178467\n",
      "step: 0, train_accuracy: 0.40064, valid_accuracy: 0.403\n",
      "step: 100, train loss: 0.2902778387069702, valid loss: 0.3322506844997406\n",
      "step: 100, train_accuracy: 0.89796, valid_accuracy: 0.8784\n",
      "step: 200, train loss: 0.2068111002445221, valid loss: 0.3105197250843048\n",
      "step: 200, train_accuracy: 0.92562, valid_accuracy: 0.8904\n"
     ]
    }
   ],
   "source": [
    "epochs = 201\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Делаем щаг градиентного спуска \n",
    "    loss = model_train(X_train, y_train_ohe)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        predict_proba = model(X_train)\n",
    "        metric_train = accuracy(predict_proba, y_train_ohe)\n",
    "        \n",
    "        predict_proba = model(X_val)\n",
    "        loss_val = logloss(predict_proba, y_val_ohe).numpy()\n",
    "        metric_val = accuracy(predict_proba, y_val_ohe)\n",
    "        \n",
    "        print(f\"step: {i}, train loss: {loss}, valid loss: {loss_val}\")\n",
    "        print(f'step: {i}, train_accuracy: {metric_train}, valid_accuracy: {metric_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9177a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
