{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Для датасета животных обучить MLP.\n",
    "2. Использовать Custom Dataset, Sampler, collate_fn\n",
    "3. Сделать различную предобработку фичей\n",
    "4. Подключить для логирования tensorboard и/или mlflow\n",
    "5. Не забыть разделить выборку на train и valid\n",
    "6. Получить точность не ниже 65%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "\n",
    "\n",
    "import mlflow\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all seeds\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_data='data/X_cat.csv', path_to_target='data/y_cat.csv'):\n",
    "    X = pd.read_csv(path_to_data, sep = '\\t', index_col=0)\n",
    "    y = pd.read_csv(path_to_target, sep = '\\t', index_col=0, names=['status'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_target(target):\n",
    "    \"\"\"\n",
    "    Perform target preprocessing\n",
    "    \"\"\"\n",
    "    target[target == 'Died'] = 'Euthanasia'\n",
    "    name_to_class = {name:cls for cls, name in enumerate(pd.unique(target))}\n",
    "    class_to_name = {cls:name for name, cls in name_to_class.items()}\n",
    "    target = target.map(name_to_class)\n",
    "    return name_to_class, class_to_name, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsDog</th>\n",
       "      <th>Age</th>\n",
       "      <th>HasName</th>\n",
       "      <th>NameLength</th>\n",
       "      <th>NameFreq</th>\n",
       "      <th>MixColor</th>\n",
       "      <th>ColorFreqAsIs</th>\n",
       "      <th>ColorFreqBase</th>\n",
       "      <th>TabbyColor</th>\n",
       "      <th>MixBreed</th>\n",
       "      <th>...</th>\n",
       "      <th>SexStatus_Flawed</th>\n",
       "      <th>SexStatus_Intact</th>\n",
       "      <th>SexStatus_Unknown</th>\n",
       "      <th>Weekday_0</th>\n",
       "      <th>Weekday_1</th>\n",
       "      <th>Weekday_2</th>\n",
       "      <th>Weekday_3</th>\n",
       "      <th>Weekday_4</th>\n",
       "      <th>Weekday_5</th>\n",
       "      <th>Weekday_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.463624</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008092</td>\n",
       "      <td>0.015005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>730.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026293</td>\n",
       "      <td>0.357521</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.285871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.058418</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.285871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.075353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsDog    Age  HasName  NameLength  NameFreq  MixColor  ColorFreqAsIs  \\\n",
       "0      1  365.0        1           7  0.000157         1       0.032919   \n",
       "1      0  365.0        1           5  0.000655         0       0.008092   \n",
       "2      1  730.0        1           6  0.000052         1       0.026293   \n",
       "3      0   21.0        0           7  0.285871         0       0.000471   \n",
       "4      1  730.0        0           7  0.285871         0       0.023831   \n",
       "\n",
       "   ColorFreqBase  TabbyColor  MixBreed  ...  SexStatus_Flawed  \\\n",
       "0       0.463624           0         1  ...                 1   \n",
       "1       0.015005           1         1  ...                 1   \n",
       "2       0.357521           0         1  ...                 1   \n",
       "3       0.058418           0         1  ...                 0   \n",
       "4       0.075353           0         0  ...                 1   \n",
       "\n",
       "   SexStatus_Intact  SexStatus_Unknown  Weekday_0  Weekday_1  Weekday_2  \\\n",
       "0                 0                  0          0          0          1   \n",
       "1                 0                  0          0          0          0   \n",
       "2                 0                  0          0          0          0   \n",
       "3                 1                  0          0          0          0   \n",
       "4                 0                  0          0          0          0   \n",
       "\n",
       "   Weekday_3  Weekday_4  Weekday_5  Weekday_6  \n",
       "0          0          0          0          0  \n",
       "1          0          0          0          1  \n",
       "2          0          0          1          0  \n",
       "3          0          1          0          0  \n",
       "4          0          1          0          0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "name_to_class_dict, class_to_name_dict, y  = preprocess_target(y['status'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclic_meta = {'cyclic_columns': ['Month', 'Day', 'Hour', 'Weekday'],\n",
    "              'cyclic_period' : [12, 31, 24, 7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sex_columns(X:pd.DataFrame)->pd.Series:\n",
    "    sex_columns = X.columns[X.columns.str.startswith('Sex_')]\n",
    "    return sex_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sex_status_columns(X:pd.DataFrame)->pd.Series:\n",
    "    sex_status_columns = X.columns[X.columns.str.startswith('SexStatus')]\n",
    "    return sex_status_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekday_columns(X: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Return columns contains weekdays \n",
    "    \"\"\"\n",
    "    weekday_columns = X.columns[X.columns.str.startswith('Week')]\n",
    "    return weekday_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_aggregate_preprocessing(X, col):\n",
    "    \"\"\"\n",
    "    Perform aggregarion over several columns\n",
    "    \"\"\"\n",
    "    aggregation_result = np.argmax(X[col].values, axis=1)\n",
    "    return aggregation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_preprocessing(x: np.array, number_unique_values:list):\n",
    "    \"\"\"\n",
    "    Apply sin and cos transformation over cyclic variable\n",
    "    \"\"\"\n",
    "    sin = np.sin(2 * np.pi * x / number_unique_values)\n",
    "    cos = np.cos(2 * np.pi * x / number_unique_values)\n",
    "    return sin, cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_column_preprocessing(X, columns, periods):\n",
    "    for col, period in zip(columns, periods):\n",
    "        X[col+'_sin'], X[col+'_cos'] = cyclic_preprocessing(X[col], number_unique_values=period)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_columns(X):\n",
    "    binary_columns = []\n",
    "    for col in X.columns:\n",
    "        if len(X[col].unique())<=2:\n",
    "            binary_columns.append(col)\n",
    "    return binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CastomDataset(Dataset):\n",
    "    def __init__(self, X, y, cyclic_meta):\n",
    "\n",
    "        self.X, self.y = X.copy(), y.copy()\n",
    "        self.X.reset_index(drop=True, inplace=True)\n",
    "        self.y = self.y.reset_index(drop=True)\n",
    "        \n",
    "        weekday_columns = get_weekday_columns(self.X)\n",
    "        sex_columns = get_sex_columns(self.X)\n",
    "        sex_status = get_sex_status_columns(self.X)\n",
    "        columns_to_drop = np.concatenate([weekday_columns.values,\n",
    "                                         sex_columns.values,\n",
    "                                         sex_status.values,\n",
    "                                         cyclic_meta['cyclic_columns']])\n",
    "        \n",
    "        self.X['Weekday'] = columns_aggregate_preprocessing(self.X, weekday_columns)\n",
    "        self.X['Gender'] = columns_aggregate_preprocessing(self.X, sex_columns)\n",
    "        self.X['Sex_status'] = columns_aggregate_preprocessing(self.X, sex_status)\n",
    "        cyclic_column_preprocessing(self.X, cyclic_meta['cyclic_columns'], cyclic_meta['cyclic_period'])\n",
    "        self.X.drop(columns=columns_to_drop, inplace=True)\n",
    "        \n",
    "        self.binary_columns = get_binary_columns(self.X)\n",
    "        self.numerical_columns = np.setdiff1d(self.X.columns.values, self.binary_columns)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        row = self.X.loc[indx,:]\n",
    "        category, numerical = row[self.binary_columns].values, row[self.numerical_columns].values\n",
    "        target = self.y[indx]\n",
    "        return category, numerical, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    category_data = []\n",
    "    numerical_data = []\n",
    "    target_data = []\n",
    "    for category, numerical, target in batch:\n",
    "        category_data.append(category)\n",
    "        numerical_data.append(numerical)\n",
    "        target_data.append(target)\n",
    "        \n",
    "    category_data = torch.LongTensor(category_data).T\n",
    "    numerical_data = torch.Tensor(numerical_data)\n",
    "    target_data = torch.LongTensor(target_data)\n",
    "    \n",
    "    return category_data, numerical_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CastomDataset(X=X_train, y=y_train,\n",
    "                        cyclic_meta=cyclic_meta)\n",
    "\n",
    "valid_dataset = CastomDataset(X=X_valid, y=y_valid,\n",
    "                        cyclic_meta=cyclic_meta)\n",
    "\n",
    "num_embedding_layers = len(train_dataset.binary_columns)\n",
    "num_numerical_features = len(train_dataset.numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 2\n",
    "NUM_CLASSES = 4\n",
    "INPUT_SIZE = EMBEDDING_DIM*num_embedding_layers+num_numerical_features\n",
    "HIDDEN_SIZE = 256\n",
    "\n",
    "BATCH_SIZE=512\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "loaders = {'train' : train_loader, 'valid': valid_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=INPUT_SIZE, num_classes=NUM_CLASSES,\n",
    "                 embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE,\n",
    "                num_embedding_layers = num_embedding_layers):\n",
    "        \n",
    "        super(SimpleNN, self).__init__()\n",
    "        \n",
    "        self.embedding_layer_list = nn.ModuleList([nn.Embedding(2, embedding_dim) for _ in range(num_embedding_layers)])\n",
    "            \n",
    "        self.batch_norm_1 = nn.BatchNorm1d(input_size)\n",
    "        self.fc_1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        \n",
    "        self.batch_norm_2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc_2 = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "        \n",
    "        self.batch_norm_3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc_3 = nn.Linear(in_features=hidden_size, out_features=num_classes)\n",
    "    \n",
    "    def forward(self, cat, num):\n",
    "        embeddings = torch.cat([layer(col) for col, layer in zip(cat, self.embedding_layer_list)], dim=-1)\n",
    "        features = torch.cat([num, embeddings], dim=-1)\n",
    "        \n",
    "        x = self.batch_norm_1(features)\n",
    "        x = self.fc_1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.batch_norm_2(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.batch_norm_3(x)\n",
    "        x = self.fc_3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_mlflow(model, loaders, criterion=criterion, optimizer=optimizer, epoches=10):\n",
    "    for epoch in tqdm(range(epoches)):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        correct_train = 0\n",
    "        correct_valid = 0\n",
    "\n",
    "        for mode, data_loader in loaders.items():\n",
    "            if mode == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            for X_cat, X_num, y_data in tqdm(data_loader):\n",
    "\n",
    "                X_cat, X_num, y_data = X_cat.to(DEVICE), X_num.to(DEVICE), y_data.to(DEVICE)\n",
    "\n",
    "                if mode == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(X_cat, X_num)\n",
    "                    loss = criterion(output, y_data)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_loss += loss.item()\n",
    "                    output = torch.softmax(output, dim=-1)\n",
    "                    predict = torch.argmax(output.cpu(), dim=-1)\n",
    "                    correct_train += (y_data.cpu()==predict).sum()\n",
    "\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        output = model(X_cat, X_num)\n",
    "                        loss = criterion(output, y_data)\n",
    "                        valid_loss += loss.item()\n",
    "                        output = torch.softmax(output, dim=-1)\n",
    "                        predict = torch.argmax(output.cpu(), dim=-1)\n",
    "                        correct_valid += (y_data.cpu()==predict).sum()\n",
    "\n",
    "        train_loss = train_loss/len(train_dataset)\n",
    "        valid_loss = valid_loss/len(valid_dataset)\n",
    "        train_accuracy = correct_train/len(train_dataset)\n",
    "        valid_accuracy = correct_valid/len(valid_dataset)\n",
    "            \n",
    "        mlflow.log_metric(\"train/loss\", float(train_loss), step=epoch)\n",
    "        mlflow.log_metric(\"valid/loss\", float(valid_loss), step=epoch)\n",
    "        mlflow.log_metric(\"train/accuracy\", float(train_accuracy), step=epoch)\n",
    "        mlflow.log_metric(\"valid/accuracy\", float(valid_accuracy), step=epoch)\n",
    "\n",
    "        print(f'Epoch: {epoch}, Train loss: {round(train_loss, 4)},  Valid loss: {round(valid_loss, 4)}')\n",
    "        print(f'Epoch: {epoch}, Train Accuracy: {train_accuracy},  Valid Accuracy: {valid_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16342ea12ee24172af83211f54aa69d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342716e7ea224daa9ec5dd611998fd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-465974f7dc72>:10: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  category_data = torch.LongTensor(category_data).T\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331dded1700142d88044c29f37345cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 0.0019,  Valid loss: 0.0049\n",
      "Epoch: 0, Train Accuracy: 0.6107655763626099,  Valid Accuracy: 0.39169472455978394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec5680831f2413aa632205022792e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e04b5822beb484692c9a38c4ec03d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.0016,  Valid loss: 0.0017\n",
      "Epoch: 1, Train Accuracy: 0.6652480959892273,  Valid Accuracy: 0.6569397449493408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c9a0a8e1a246b2ba240da3ac93c488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b301472ed14f4ddc8dbef47a5c41978e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.0015,  Valid loss: 0.0017\n",
      "Epoch: 2, Train Accuracy: 0.6753028035163879,  Valid Accuracy: 0.6580621004104614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d98e8550e7248c49506480171b1a99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef134807baa441d861eb16896a1ba0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.0015,  Valid loss: 0.0017\n",
      "Epoch: 3, Train Accuracy: 0.6850301623344421,  Valid Accuracy: 0.6593714952468872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c733ea06bc4aad8fb6970726204b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8ccd8133a54b6ea59cbcac4e02e5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.0014,  Valid loss: 0.0017\n",
      "Epoch: 4, Train Accuracy: 0.6926062703132629,  Valid Accuracy: 0.6595585346221924\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5edcc1ffd7849cfa1ca2c9ad67451c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e43b38e7dc4ac6b5abdf7cc2564ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 0.0014,  Valid loss: 0.0017\n",
      "Epoch: 5, Train Accuracy: 0.699106752872467,  Valid Accuracy: 0.6582491397857666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c245e456c41f444296ef1a67f0f66dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c63c08ac0e46db99b591a139c18827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 0.0014,  Valid loss: 0.0017\n",
      "Epoch: 6, Train Accuracy: 0.7071505188941956,  Valid Accuracy: 0.6560044884681702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76062d532335435a9212d082f4c51fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cc5041a3ee480abc45700032376c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 0.0013,  Valid loss: 0.0017\n",
      "Epoch: 7, Train Accuracy: 0.7149137258529663,  Valid Accuracy: 0.655817449092865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fdfee1d0be488b98bf793546c10c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abdf2c3ee5c493995fe48acf903deed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 0.0013,  Valid loss: 0.0017\n",
      "Epoch: 8, Train Accuracy: 0.7206192016601562,  Valid Accuracy: 0.650954008102417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a2138f3e1d404ca850c02bc5bef575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9350e9fead7e4f28b7594bfd858e5afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 0.0013,  Valid loss: 0.0017\n",
      "Epoch: 9, Train Accuracy: 0.729832112789154,  Valid Accuracy: 0.6498316526412964\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "try:\n",
    "    experiment_id = client.create_experiment(\"MLflow_experiment_mlp\")\n",
    "except MlflowException:  # If such experiment already exist\n",
    "    experiment_id = client.get_experiment_by_name(\"MLflow_experiment_mlp\").experiment_id\n",
    "        \n",
    "with mlflow.start_run(run_name='MLFlow_run', experiment_id=experiment_id):\n",
    "    \n",
    "    EPOCHES = 10\n",
    "    mlflow.log_param(\"optimizer\", 'Adam')\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"embedding_dim\", EMBEDDING_DIM)\n",
    "    mlflow.log_param(\"epoches\", EPOCHES)\n",
    "\n",
    "    experiment_mlflow(model, loaders, epoches=EPOCHES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard\n",
    "(Just to try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "train_writer = SummaryWriter('./logs/train')\n",
    "valid_writer = SummaryWriter('./logs/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_tensorboard(model, loaders, criterion=criterion, optimizer=optimizer, epoches=10):\n",
    "    for epoch in tqdm(range(epoches)):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        correct_train = 0\n",
    "        correct_valid = 0\n",
    "\n",
    "        for mode, data_loader in loaders.items():\n",
    "            if mode == 'valid':\n",
    "                model.eval()\n",
    "            else:\n",
    "                model.train()\n",
    "\n",
    "            for X_cat, X_num, y_data in tqdm(data_loader):\n",
    "\n",
    "                X_cat, X_num, y_data = X_cat.to(DEVICE), X_num.to(DEVICE), y_data.to(DEVICE)\n",
    "\n",
    "                if mode == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(X_cat, X_num)\n",
    "                    loss = criterion(output, y_data)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_loss += loss.item()\n",
    "                    output = torch.softmax(output, dim=-1)\n",
    "                    predict = torch.argmax(output.cpu(), dim=-1)\n",
    "                    correct_train += (y_data.cpu()==predict).sum()\n",
    "\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        output = model(X_cat, X_num)\n",
    "                        loss = criterion(output, y_data)\n",
    "                        valid_loss += loss.item()\n",
    "                        output = torch.softmax(output, dim=-1)\n",
    "                        predict = torch.argmax(output.cpu(), dim=-1)\n",
    "                        correct_valid += (y_data.cpu()==predict).sum()\n",
    "\n",
    "        train_loss = train_loss/len(train_dataset)\n",
    "        valid_loss = valid_loss/len(valid_dataset)\n",
    "        train_accuracy = correct_train/len(train_dataset)\n",
    "        valid_accuracy = correct_valid/len(valid_dataset)\n",
    "            \n",
    "        train_writer.add_scalar(\"loss\", float(train_loss), epoch)\n",
    "        valid_writer.add_scalar(\"loss\", float(valid_loss), epoch)\n",
    "        train_writer.add_scalar(\"accuracy\", float(train_accuracy), epoch)\n",
    "        valid_writer.add_scalar(\"accuracy\", float(valid_accuracy), epoch)\n",
    "\n",
    "        print(f'Epoch: {epoch}, Train loss: {round(train_loss, 4)},  Valid loss: {round(valid_loss, 4)}')\n",
    "        print(f'Epoch: {epoch}, Train Accuracy: {train_accuracy},  Valid Accuracy: {valid_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_board = SimpleNN().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_board.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea72a63e02742df8e15966f12ff008e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d2cea823824a41939525c1818a674e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-116-465974f7dc72>:10: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  category_data = torch.LongTensor(category_data).T\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713af1af3cb846e3a5c7180f832675db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 0.0019,  Valid loss: 0.0023\n",
      "Epoch: 0, Train Accuracy: 0.6030958890914917,  Valid Accuracy: 0.5725776553153992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a257f3b19d7d451384b5e68a22da9774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439d7bcc5bfa430db00ef58f4e596d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.0017,  Valid loss: 0.0018\n",
      "Epoch: 1, Train Accuracy: 0.6619744896888733,  Valid Accuracy: 0.654321014881134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174c457a4d2d43ac8519214b4ca9ed6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa73a2fa0c2d4ec2a4e118361100421a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.0016,  Valid loss: 0.0017\n",
      "Epoch: 2, Train Accuracy: 0.6731048226356506,  Valid Accuracy: 0.6597456336021423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33571dbbd8264691925d432265efc322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a51a3b527924cf28aa86fd36096b5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.0015,  Valid loss: 0.0017\n",
      "Epoch: 3, Train Accuracy: 0.6837674975395203,  Valid Accuracy: 0.6582491397857666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23426c1c592f4a4bade87a549d6a8f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374baa134b8844b384656edeb9b113cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.0015,  Valid loss: 0.0017\n",
      "Epoch: 4, Train Accuracy: 0.690782368183136,  Valid Accuracy: 0.6589973568916321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc57ac7daf742f485b10d952cacd433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a6d46700a34a6eb47566092173d8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 0.0014,  Valid loss: 0.0017\n",
      "Epoch: 5, Train Accuracy: 0.698077917098999,  Valid Accuracy: 0.6563786268234253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64708c8223e64b41b7c94bfdd7771ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2c62cf2d3a4cc09af9ae98796bd680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 0.0014,  Valid loss: 0.0017\n",
      "Epoch: 6, Train Accuracy: 0.7063555121421814,  Valid Accuracy: 0.6560044884681702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2c0948c42f442cbfbe4b0c6bcaac2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fae797bcbe406c953a8a4106d306a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 0.0014,  Valid loss: 0.0017\n",
      "Epoch: 7, Train Accuracy: 0.7143992781639099,  Valid Accuracy: 0.6541339159011841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71a33ffa12e482d898a6a343709519b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201f6f4dd1da47309ae811f210a3769a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 0.0013,  Valid loss: 0.0017\n",
      "Epoch: 8, Train Accuracy: 0.7211803793907166,  Valid Accuracy: 0.6515151262283325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0826c17a75f64a6b8c4553772195808c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24172a4c72b94348ac2530eac814ca87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 0.0013,  Valid loss: 0.0017\n",
      "Epoch: 9, Train Accuracy: 0.7302062511444092,  Valid Accuracy: 0.6513280868530273\n"
     ]
    }
   ],
   "source": [
    "EPOCHES = 10\n",
    "train_writer.add_text(\"optimizer\", 'Adam')\n",
    "train_writer.add_text('learning_rate', str(LEARNING_RATE))\n",
    "train_writer.add_text('embedding_dim', str(EMBEDDING_DIM))\n",
    "train_writer.add_text('batch_size', str(BATCH_SIZE))\n",
    "train_writer.add_text('epoches', str(EPOCHES))\n",
    "\n",
    "train_writer.add_graph(model, example_batch[:2], verbose=False)\n",
    "\n",
    "experiment_tensorboard(model_board, loaders, criterion=criterion, optimizer=optimizer, epoches=EPOCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
